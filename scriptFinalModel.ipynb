{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import LambdaLR, ExponentialLR, StepLR, CosineAnnealingLR\n",
    "from torch.optim import AdamW\n",
    "from models import *\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CIFAR 10 Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of Train Data batches (Enhanced): 1250\n",
      "Amount of Valid Data batches: 157\n",
      "Amount of training images (Enhanced): 80000\n",
      "Amount of Validation images: 10000\n"
     ]
    }
   ],
   "source": [
    "# Function to load a batch file and return a dictionary\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Load dataset, combine batches, split, and visualize images\n",
    "def load_and_prepare_data():\n",
    "    # Load and combine the training batches\n",
    "    data_batches, label_batches = [], []\n",
    "    for i in range(1, 6):\n",
    "        batch = unpickle(f'data/KaggleData/cifar-10-python/cifar-10-batches-py/data_batch_{i}')\n",
    "        data_batches.append(batch[b'data'])\n",
    "        label_batches.append(batch[b'labels'])\n",
    "    X, y = np.concatenate(data_batches), np.concatenate(label_batches)\n",
    "    \n",
    "    # Split into training and validation sets (80-20 split)\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = load_and_prepare_data()\n",
    "\n",
    "# Define transformations\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "transformations = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
    "        transforms.RandomHorizontalFlip(), \n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.RandomApply([transforms.RandomErasing()], p=0.5),\n",
    "        transforms.Normalize(*stats)]),\n",
    "        \n",
    "    'valid': transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(*stats)]),\n",
    "        \n",
    "    # Normalization only for 'train_Default' scenario\n",
    "    'normalization_only': transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(*stats)])\n",
    "}\n",
    "\n",
    "# Adjusting the CIFAR10Dataset class initialization to accept 'data_mode'\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, data_mode='default'):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.data_mode = data_mode\n",
    "        if data_mode == 'train_Enhanced':\n",
    "            self.data = np.concatenate((self.data, self.data), axis=0)\n",
    "            self.labels = np.concatenate((self.labels, self.labels), axis=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.data_mode == 'train_Enhanced' and idx >= len(self.labels) // 2:\n",
    "            transform = transformations['train']\n",
    "        else:\n",
    "            transform = self.transform\n",
    "        image = self.data[idx % len(self.labels)].reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "        image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "        image = transform(image)\n",
    "        return image, self.labels[idx % len(self.labels)]\n",
    "\n",
    "# Create datasets and DataLoader instances\n",
    "datasets = {\n",
    "    'train_Enhanced': CIFAR10Dataset(X_train, y_train, transform=transformations['normalization_only'], data_mode='train_Enhanced'),\n",
    "    'valid': CIFAR10Dataset(X_val, y_val, transform=transformations['valid'])\n",
    "}\n",
    "\n",
    "# Update loaders for each dataset\n",
    "loaders = {\n",
    "    'train_Enhanced': DataLoader(datasets['train_Enhanced'], batch_size=64, shuffle=True,num_workers=0),\n",
    "    'valid': DataLoader(datasets['valid'], batch_size=64, shuffle=False,num_workers=0)\n",
    "}\n",
    "\n",
    "print('Amount of Train Data batches (Enhanced):', len(loaders['train_Enhanced']))\n",
    "print('Amount of Valid Data batches:', len(loaders['valid']))\n",
    "\n",
    "print('Amount of training images (Enhanced):', len(datasets['train_Enhanced']))\n",
    "print('Amount of Validation images:', len(X_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_batch_images, first_batch_labels = next(iter(loaders['train_Enhanced']))\n",
    "# print(f\"First batch images shape: {first_batch_images.shape}\")\n",
    "# print(f\"First batch labels shape: {first_batch_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #visualize:\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from torchvision.transforms import ToPILImage\n",
    "# from random import sample\n",
    "\n",
    "# # Define a function to show images in a grid\n",
    "# def show_images(images, labels, classes, rows=2, cols=5, scale=2):\n",
    "#     fig, axes = plt.subplots(rows, cols, figsize=(scale*cols, scale*rows))\n",
    "#     axes = axes.flatten()\n",
    "#     for img, label, ax in zip(images, labels, axes):\n",
    "#         img = img.reshape(3, 32, 32).transpose(1, 2, 0)  # Convert to HxWxC format\n",
    "#         if np.max(img) > 1:  # Assume the image is in the range [0, 255]\n",
    "#             img = img / 255.0\n",
    "#         ax.imshow(img)\n",
    "#         ax.axis('off')\n",
    "#         ax.set_title(classes[label])\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Classes in CIFAR-10\n",
    "# classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "#            'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# # Randomly select 10 images and their labels from training set\n",
    "# indices_train = sample(range(len(X_train)), 10)\n",
    "# images_train = X_train[indices_train]\n",
    "# labels_train = y_train[indices_train]\n",
    "\n",
    "# # Randomly select 10 images and their labels from validation set\n",
    "# indices_val = sample(range(len(X_val)), 10)\n",
    "# images_val = X_val[indices_val]\n",
    "# labels_val = y_val[indices_val]\n",
    "\n",
    "# # Display training images\n",
    "# print(\"Training Images:\")\n",
    "# show_images(images_train, labels_train, classes)\n",
    "\n",
    "# # Display validation images\n",
    "# print(\"Validation Images:\")\n",
    "# show_images(images_val, labels_val, classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model finetuning\n",
    "\n",
    "### 1st  Test: Architecture Test:\n",
    "\n",
    "- Test number of Layers (4 Training Runs): \n",
    "\n",
    "     train with 2,3,4,5 layers [same amount of blocks for all layers [2,2,2,2], Similar amount of Conv-featuremaps for each layer [2layers: 64,256],[3 Layers: 64,128,256],[4Layers: 64,128,128,256]], [5 Layers: 64,64,128,128,256] \n",
    "\n",
    "- Test best Config of Blocks per Layer (4 Training Runs):\n",
    "\n",
    "     Suppose the prev. test returned that 4 layers gives best valid accuracy: Run through training with 4 permutations of Blocks Per Layers (only choose either 3 or 2 blocks per layer to keep it simple) \n",
    "\n",
    "Goal: Figure out best Architecture by finding optimal Amount of Layers, and optimal Amount of Blocks per Layer.\n",
    "\n",
    "Guidelines for Architecture Test: No Dropouts, and no Data Augmentation (but normalization)\n",
    "\n",
    "### 2nd Test: Training Parameter Gridsearch\n",
    "\n",
    "2nd Test: Hyperparameter Gridsearch:\n",
    "- Learning Rate (4 tests)\n",
    "\n",
    "     LR set to [0.1, 0.01, 0.001, 0.0001] (while using ADAM as Optimizer, no LR scheduler)\n",
    "\n",
    "- Optimizer: (4 tests)\n",
    "     \n",
    "     Having figured out best LR, test different Optimizers: SGD, ADAM, ADAMW(0.01) (3 Training Runs)\n",
    "     if ADAMW returns best Valid Acc. figure out which weight decay to use [0.1,0.01,0.001,0.0001] \n",
    "\n",
    "- Exponential scheduler or not (2 differenttests. Exponential LR with gamma 0.98)\n",
    "\n",
    "Goal: Figure out best set of training-setup\n",
    "\n",
    "### 3rd Test: Data ingestion Method: \n",
    "- Batchsize [ 32, ,64, 128, 256] (4 tests)\n",
    "- Augmentation (Random Flipping, cropping) (3 Tests)\n",
    "\n",
    "     1. No Augmentation applied, \n",
    "     2. With Random Flipping and Cropping, \n",
    "     3. With Random and Cropping but copying the Altered images on top of the original training data (increase training images from 40k to 80k)     \n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters modelResnet3_443: 4697162\n",
      "NVIDIA GeForce RTX 4070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet3(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Resnet3_443Exp():\n",
    "    return ResNet3(BasicBlock, [4,4,3])\n",
    "\n",
    "model = Resnet3_443Exp()\n",
    "\n",
    "total_paramsResnet3_443 = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters modelResnet3_443: {total_paramsResnet3_443}\")\n",
    "\n",
    "# Move the model to CUDA device if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_and_evaluate_model(model, model_name, loaders, device, num_epochs=1):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    train_loss_history, valid_loss_history, valid_accuracy_history, train_accuracy_history = [], [], [], []\n",
    "    best_accuracy = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss, total_train_loss, total_correct_train, num_batches, num_train_examples = 0.0, 0.0, 0, 0, 0\n",
    "        for i, (inputs, labels) in enumerate(loaders[\"train_Enhanced\"]):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),0.1)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            total_train_loss += loss.item() * inputs.size(0)\n",
    "            num_batches += 1\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct_train += (predicted == labels).sum().item()\n",
    "            num_train_examples += labels.size(0)\n",
    "\n",
    "            if (i + 1) % 100 == 0 or i == len(loaders[\"train_Enhanced\"]) - 1:\n",
    "                print(f\"{model_name}, train_Enhanced - Epoch: {epoch} [{(i + 1) * len(inputs)}/{len(loaders['train_Enhanced'].dataset)} \"\n",
    "                      f\"({100. * (i + 1) / len(loaders['train_Enhanced']):.0f}%)], Weight Decay: 0.0001,  Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "        avg_train_loss = total_train_loss / num_train_examples  # Correct average training loss calculation\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "\n",
    "        train_accuracy = 100. * total_correct_train / num_train_examples\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "        model.eval()\n",
    "        total_valid_loss, total_correct_valid, num_valid_batches = 0.0, 0, 0\n",
    "        for inputs, labels in loaders['valid']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.long()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_valid_loss += loss.item() * inputs.size(0)  # Update to multiply by batch size for total loss\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct_valid += (predicted == labels).sum().item()\n",
    "            num_valid_batches += 1\n",
    "\n",
    "        avg_valid_loss = total_valid_loss / len(loaders['valid'].dataset)  # Correct average validation loss calculation\n",
    "        valid_loss_history.append(avg_valid_loss)\n",
    "\n",
    "        valid_accuracy = 100. * total_correct_valid / len(loaders['valid'].dataset)\n",
    "        valid_accuracy_history.append(valid_accuracy)\n",
    "\n",
    "        print(f\"End of Epoch: {epoch}, Avg. Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, Avg. Valid Loss: {avg_valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.2f}%\")\n",
    "\n",
    "        if valid_accuracy > best_accuracy:\n",
    "            best_accuracy = valid_accuracy\n",
    "            model_path = f'{model_name}_Final_best_model.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"New best model saved: {model_path}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "    print(f\"Training completed. Total execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "    return train_loss_history, valid_loss_history, valid_accuracy_history, train_accuracy_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters modelResnet3_443_30DR: 4697162\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 2.0818\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 1.9390\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 1.8458\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 1.7741\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 1.7189\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 1.6697\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 1.6291\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 1.5897\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 1.5560\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 1.5270\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 1.4969\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 1.4718\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 1.4584\n",
      "End of Epoch: 1, Avg. Training Loss: 1.4584, Training Accuracy: 46.35%, Avg. Valid Loss: 1.2706, Valid Accuracy: 55.92%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 1.1167\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 1.1088\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 1.0922\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 1.0779\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 1.0644\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 1.0546\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 1.0448\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 1.0328\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 1.0206\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 1.0104\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 1.0005\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.9909\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.9862\n",
      "End of Epoch: 2, Avg. Training Loss: 0.9862, Training Accuracy: 65.10%, Avg. Valid Loss: 0.7222, Valid Accuracy: 74.29%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.8317\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.8337\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.8189\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.8157\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.8118\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.8034\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.7956\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.7881\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.7808\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.7730\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.7676\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.7620\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.7590\n",
      "End of Epoch: 3, Avg. Training Loss: 0.7590, Training Accuracy: 73.56%, Avg. Valid Loss: 0.6258, Valid Accuracy: 78.44%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.6568\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.6536\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.6444\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.6443\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.6422\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.6387\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.6389\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.6365\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.6324\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.6289\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.6268\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.6231\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.6208\n",
      "End of Epoch: 4, Avg. Training Loss: 0.6208, Training Accuracy: 78.44%, Avg. Valid Loss: 0.5156, Valid Accuracy: 82.42%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.5501\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.5440\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.5426\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.5456\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.5443\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.5437\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.5396\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.5376\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.5364\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.5352\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.5328\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.5309\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.5300\n",
      "End of Epoch: 5, Avg. Training Loss: 0.5300, Training Accuracy: 81.68%, Avg. Valid Loss: 0.5613, Valid Accuracy: 80.91%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.4697\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.4643\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.4731\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.4737\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.4673\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.4663\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.4638\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.4647\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.4627\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.4627\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.4611\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.4597\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.4593\n",
      "End of Epoch: 6, Avg. Training Loss: 0.4593, Training Accuracy: 84.13%, Avg. Valid Loss: 0.4121, Valid Accuracy: 86.22%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.4116\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.4152\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.4156\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.4162\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.4127\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.4116\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.4102\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.4102\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.4094\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.4087\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.4059\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.4039\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.4029\n",
      "End of Epoch: 7, Avg. Training Loss: 0.4029, Training Accuracy: 86.12%, Avg. Valid Loss: 0.4030, Valid Accuracy: 86.72%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.3743\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.3729\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.3660\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.3687\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.3679\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.3681\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.3695\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.3672\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.3640\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.3641\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.3627\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.3624\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.3622\n",
      "End of Epoch: 8, Avg. Training Loss: 0.3622, Training Accuracy: 87.53%, Avg. Valid Loss: 0.4825, Valid Accuracy: 85.11%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.3241\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.3244\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.3205\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.3229\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.3240\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.3270\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.3273\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.3280\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.3279\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.3295\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.3276\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.3265\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.3265\n",
      "End of Epoch: 9, Avg. Training Loss: 0.3265, Training Accuracy: 88.83%, Avg. Valid Loss: 0.3504, Valid Accuracy: 88.93%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.2919\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2991\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.3058\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.3053\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.3054\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.3010\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.3007\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.3014\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.3015\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.3028\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.3018\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.3005\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.3009\n",
      "End of Epoch: 10, Avg. Training Loss: 0.3009, Training Accuracy: 89.67%, Avg. Valid Loss: 0.3886, Valid Accuracy: 87.42%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.2944\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2798\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.2777\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.2831\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.2785\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.2796\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.2783\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.2791\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.2805\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.2800\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.2803\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.2799\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.2800\n",
      "End of Epoch: 11, Avg. Training Loss: 0.2800, Training Accuracy: 90.44%, Avg. Valid Loss: 0.3459, Valid Accuracy: 89.25%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.2456\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2455\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.2549\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.2549\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.2555\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.2566\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.2566\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.2554\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.2561\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.2557\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.2555\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.2570\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.2568\n",
      "End of Epoch: 12, Avg. Training Loss: 0.2568, Training Accuracy: 91.25%, Avg. Valid Loss: 0.3687, Valid Accuracy: 89.05%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.2275\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2265\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.2254\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.2319\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.2345\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.2377\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.2375\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.2393\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.2395\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.2404\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.2407\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.2400\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.2401\n",
      "End of Epoch: 13, Avg. Training Loss: 0.2401, Training Accuracy: 91.76%, Avg. Valid Loss: 0.3406, Valid Accuracy: 90.29%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.2142\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2099\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.2164\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.2207\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.2191\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.2181\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.2203\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.2208\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.2209\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.2203\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.2216\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.2220\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.2217\n",
      "End of Epoch: 14, Avg. Training Loss: 0.2217, Training Accuracy: 92.49%, Avg. Valid Loss: 0.3382, Valid Accuracy: 90.50%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.2036\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2125\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.2102\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.2074\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.2108\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.2134\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.2126\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.2122\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.2134\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.2136\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.2127\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.2119\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.2131\n",
      "End of Epoch: 15, Avg. Training Loss: 0.2131, Training Accuracy: 92.82%, Avg. Valid Loss: 0.3487, Valid Accuracy: 90.31%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.1938\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2001\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.1988\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.2016\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.2026\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.2038\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.2028\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.2029\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.2033\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.2021\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.2011\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.2023\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.2029\n",
      "End of Epoch: 16, Avg. Training Loss: 0.2029, Training Accuracy: 93.09%, Avg. Valid Loss: 0.3427, Valid Accuracy: 90.39%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.1717\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.1839\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.1883\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.1899\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.1895\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.1901\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.1929\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.1962\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.1956\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.1959\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.1955\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.1963\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.1964\n",
      "End of Epoch: 17, Avg. Training Loss: 0.1964, Training Accuracy: 93.39%, Avg. Valid Loss: 0.3997, Valid Accuracy: 89.57%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.1676\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.1746\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.1750\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.1779\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.1775\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.1784\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.1805\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.1798\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.1803\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.1812\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.1820\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.1819\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.1824\n",
      "End of Epoch: 18, Avg. Training Loss: 0.1824, Training Accuracy: 93.87%, Avg. Valid Loss: 0.3442, Valid Accuracy: 90.60%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.1625\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.1663\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.1741\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.1753\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.1741\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.1736\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.1725\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.1743\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.1743\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.1747\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.1762\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.1756\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.1760\n",
      "End of Epoch: 19, Avg. Training Loss: 0.1760, Training Accuracy: 94.05%, Avg. Valid Loss: 0.3648, Valid Accuracy: 90.53%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.1680\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.1689\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.1710\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.1739\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.1747\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.1743\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.1750\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.1753\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.1754\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.1748\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Re-initialize the model for each weight decay to ensure training starts fresh\u001b[39;00m\n\u001b[0;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet3_with_dropout_30DR()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 21\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodelResnet3_443_30DR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Unpack and store the returned metrics\u001b[39;00m\n\u001b[0;32m     25\u001b[0m all_metrics_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m'\u001b[39m], \\\n\u001b[0;32m     26\u001b[0m all_metrics_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_losses\u001b[39m\u001b[38;5;124m'\u001b[39m], \\\n\u001b[0;32m     27\u001b[0m all_metrics_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_accuracies\u001b[39m\u001b[38;5;124m'\u001b[39m], \\\n\u001b[0;32m     28\u001b[0m all_metrics_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_accuracies\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m metrics\n",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[1;34m(model, model_name, loaders, device, num_epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\Documents\\PythonProjects\\DeepLearning\\DL_Sp24_Miniproject\\models.py:62\u001b[0m, in \u001b[0;36mResNet3Dropouts.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     60\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(out)\n\u001b[0;32m     61\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(out)\n\u001b[1;32m---> 62\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(out)\n\u001b[0;32m     64\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(out\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\Documents\\PythonProjects\\DeepLearning\\DL_Sp24_Miniproject\\models.py:26\u001b[0m, in \u001b[0;36mBasicBlockDropouts.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 26\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(out)  \u001b[38;5;66;03m# Apply dropout after activation (new proposed method) https://arxiv.org/pdf/1904.03392.pdf\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out))\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\functional.py:1471\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 200  # Or any other number of epochs you want to train for\n",
    "\n",
    "all_metrics_final = {\n",
    "    'train_losses': [],\n",
    "    'valid_losses': [],\n",
    "    'valid_accuracies': [],\n",
    "    'train_accuracies': []\n",
    "}\n",
    "\n",
    "def ResNet3_with_dropout_30DR():\n",
    "    return ResNet3Dropouts(BasicBlockDropouts, [4, 4, 3], dropout_rate=0.3)  # For example, a dropout rate of 0.5\n",
    "\n",
    "modelResnet3_443_30DR = ResNet3_with_dropout_30DR()\n",
    "total_paramsResnet3_443_30DR = sum(p.numel() for p in modelResnet3_443_30DR.parameters())\n",
    "print(f\"Total parameters modelResnet3_443_30DR: {total_paramsResnet3_443_30DR}\")\n",
    "\n",
    "# Re-initialize the model for each weight decay to ensure training starts fresh\n",
    "model = ResNet3_with_dropout_30DR().to(device)\n",
    "metrics = train_and_evaluate_model(model, \"modelResnet3_443_30DR\", loaders, device, num_epochs)\n",
    "\n",
    "\n",
    "# Unpack and store the returned metrics\n",
    "all_metrics_final['train_losses'], \\\n",
    "all_metrics_final['valid_losses'], \\\n",
    "all_metrics_final['valid_accuracies'], \\\n",
    "all_metrics_final['train_accuracies'] = metrics\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Training Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(all_metrics_final['train_losses'], label='Train Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Validation Loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(all_metrics_final['valid_losses'], label='Validation Loss')\n",
    "plt.title('Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Validation Accuracy\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(all_metrics_final['valid_accuracies'], label='Validation Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "# Training Accuracy\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(all_metrics_final['train_accuracies'], label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet3Dropouts(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlockDropouts(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlockDropouts(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlockDropouts(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlockDropouts(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlockDropouts(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlockDropouts(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlockDropouts(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlockDropouts(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlockDropouts(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlockDropouts(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlockDropouts(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout1): Dropout(p=0.0, inplace=False)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best Model\n",
    "model_path = 'modelResnet3_443_30DR_Final_best_model.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test images:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "test_data_dict = unpickle('./data/cifar_test_nolabels.pkl')\n",
    "test_images = test_data_dict[b'data']\n",
    "test_images = test_images.reshape(-1, 3, 32, 32)\n",
    "\n",
    "# Modified function to show random images\n",
    "def show_original_random_images(images, rows=2, cols=5):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
    "    indices = np.random.choice(len(images), rows*cols, replace=False)  # Select random indices\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Use the random index to select an image\n",
    "        img = images[indices[i]].transpose(1, 2, 0)\n",
    "        ax.imshow(img.astype('uint8'))\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print('test images:')\n",
    "# Show 10 random original images\n",
    "show_original_random_images(test_images, rows=2, cols=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modelResnet3_443_30DR_Final_best_model.pth'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'submission.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Best Model, Normalize test data, do an inference and create submission csv file\n",
    "\n",
    "# Convert test_images to a float tensor\n",
    "test_images = torch.from_numpy(test_images).float()\n",
    "\n",
    "# If the pixel values are in [0,255], scale them to [0,1]\n",
    "if test_images.max() > 1.0:\n",
    "    test_images /= 255.0\n",
    "\n",
    "# Permute the images to [N, C, H, W] format\n",
    "test_images = test_images.permute(0, 1, 2, 3)\n",
    "\n",
    "\n",
    "# Define the normalization transform\n",
    "normalize = transforms.Normalize(*stats) #takes mean and std from loadingand transforming the validation data\n",
    "\n",
    "# Normalize the images\n",
    "normalized_images = torch.stack([normalize(img) for img in test_images])\n",
    "\n",
    "# Make sure your model is on the right device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#load best model.pth\n",
    "# model.load_state_dict(torch.load('best_model.pth'))\n",
    "# Load the model state dict into the model\n",
    "\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Now, ensure your input data is also sent to the same device\n",
    "normalized_images = normalized_images.to(device)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():  # No need to track gradients\n",
    "    for img in normalized_images:\n",
    "        img = img.unsqueeze(0).to(device)  # Add batch dimension and ensure the tensor is on the right device\n",
    "        output = model(img)  # Process each image individually\n",
    "        pred = output.argmax(dim=1)  # Get the index of the max log-probability\n",
    "        predictions.append(pred.item())\n",
    "print(len(predictions))\n",
    "\n",
    "# Create a DataFrame with the ID and predicted Labels\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': list(range(len(predictions))),\n",
    "    'Labels': predictions\n",
    "})\n",
    "\n",
    "# Define the submission CSV file path\n",
    "submission_csv_path = 'submission.csv'\n",
    "# Save the DataFrame to a CSV file, without the index\n",
    "submission_df.to_csv(submission_csv_path, index=False)\n",
    "\n",
    "# Returning the path to the saved CSV file\n",
    "submission_csv_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
