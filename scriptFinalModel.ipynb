{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import LambdaLR, ExponentialLR, StepLR, CosineAnnealingLR\n",
    "from torch.optim import AdamW\n",
    "from models import *\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CIFAR 10 Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of Train Data batches (Enhanced): 1250\n",
      "Amount of Valid Data batches: 157\n",
      "Amount of training images (Enhanced): 80000\n",
      "Amount of Validation images: 10000\n"
     ]
    }
   ],
   "source": [
    "# Function to load a batch file and return a dictionary\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# Load dataset, combine batches, split, and visualize images\n",
    "def load_and_prepare_data():\n",
    "    # Load and combine the training batches\n",
    "    data_batches, label_batches = [], []\n",
    "    for i in range(1, 6):\n",
    "        batch = unpickle(f'data/KaggleData/cifar-10-python/cifar-10-batches-py/data_batch_{i}')\n",
    "        data_batches.append(batch[b'data'])\n",
    "        label_batches.append(batch[b'labels'])\n",
    "    X, y = np.concatenate(data_batches), np.concatenate(label_batches)\n",
    "    \n",
    "    # Split into training and validation sets (80-20 split)\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = load_and_prepare_data()\n",
    "\n",
    "# Define transformations\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "transformations = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4, padding_mode='reflect'), \n",
    "        transforms.RandomHorizontalFlip(), \n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(), \n",
    "        transforms.RandomApply([transforms.RandomErasing()], p=0.5),\n",
    "        transforms.Normalize(*stats)]),\n",
    "        \n",
    "    'valid': transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(*stats)]),\n",
    "        \n",
    "    # Normalization only for 'train_Default' scenario\n",
    "    'normalization_only': transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        transforms.Normalize(*stats)])\n",
    "}\n",
    "\n",
    "# Adjusting the CIFAR10Dataset class initialization to accept 'data_mode'\n",
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, data_mode='default'):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.data_mode = data_mode\n",
    "        if data_mode == 'train_Enhanced':\n",
    "            self.data = np.concatenate((self.data, self.data), axis=0)\n",
    "            self.labels = np.concatenate((self.labels, self.labels), axis=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.data_mode == 'train_Enhanced' and idx >= len(self.labels) // 2:\n",
    "            transform = transformations['train']\n",
    "        else:\n",
    "            transform = self.transform\n",
    "        image = self.data[idx % len(self.labels)].reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "        image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "        image = transform(image)\n",
    "        return image, self.labels[idx % len(self.labels)]\n",
    "\n",
    "# Create datasets and DataLoader instances\n",
    "datasets = {\n",
    "    'train_Enhanced': CIFAR10Dataset(X_train, y_train, transform=transformations['normalization_only'], data_mode='train_Enhanced'),\n",
    "    'valid': CIFAR10Dataset(X_val, y_val, transform=transformations['valid'])\n",
    "}\n",
    "\n",
    "# Update loaders for each dataset\n",
    "loaders = {\n",
    "    'train_Enhanced': DataLoader(datasets['train_Enhanced'], batch_size=64, shuffle=True,num_workers=0),\n",
    "    'valid': DataLoader(datasets['valid'], batch_size=64, shuffle=False,num_workers=0)\n",
    "}\n",
    "\n",
    "print('Amount of Train Data batches (Enhanced):', len(loaders['train_Enhanced']))\n",
    "print('Amount of Valid Data batches:', len(loaders['valid']))\n",
    "\n",
    "print('Amount of training images (Enhanced):', len(datasets['train_Enhanced']))\n",
    "print('Amount of Validation images:', len(X_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_batch_images, first_batch_labels = next(iter(loaders['train_Enhanced']))\n",
    "# print(f\"First batch images shape: {first_batch_images.shape}\")\n",
    "# print(f\"First batch labels shape: {first_batch_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #visualize:\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from torchvision.transforms import ToPILImage\n",
    "# from random import sample\n",
    "\n",
    "# # Define a function to show images in a grid\n",
    "# def show_images(images, labels, classes, rows=2, cols=5, scale=2):\n",
    "#     fig, axes = plt.subplots(rows, cols, figsize=(scale*cols, scale*rows))\n",
    "#     axes = axes.flatten()\n",
    "#     for img, label, ax in zip(images, labels, axes):\n",
    "#         img = img.reshape(3, 32, 32).transpose(1, 2, 0)  # Convert to HxWxC format\n",
    "#         if np.max(img) > 1:  # Assume the image is in the range [0, 255]\n",
    "#             img = img / 255.0\n",
    "#         ax.imshow(img)\n",
    "#         ax.axis('off')\n",
    "#         ax.set_title(classes[label])\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Classes in CIFAR-10\n",
    "# classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "#            'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# # Randomly select 10 images and their labels from training set\n",
    "# indices_train = sample(range(len(X_train)), 10)\n",
    "# images_train = X_train[indices_train]\n",
    "# labels_train = y_train[indices_train]\n",
    "\n",
    "# # Randomly select 10 images and their labels from validation set\n",
    "# indices_val = sample(range(len(X_val)), 10)\n",
    "# images_val = X_val[indices_val]\n",
    "# labels_val = y_val[indices_val]\n",
    "\n",
    "# # Display training images\n",
    "# print(\"Training Images:\")\n",
    "# show_images(images_train, labels_train, classes)\n",
    "\n",
    "# # Display validation images\n",
    "# print(\"Validation Images:\")\n",
    "# show_images(images_val, labels_val, classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model finetuning\n",
    "\n",
    "### 1st  Test: Architecture Test:\n",
    "\n",
    "- Test number of Layers (4 Training Runs): \n",
    "\n",
    "     train with 2,3,4,5 layers [same amount of blocks for all layers [2,2,2,2], Similar amount of Conv-featuremaps for each layer [2layers: 64,256],[3 Layers: 64,128,256],[4Layers: 64,128,128,256]], [5 Layers: 64,64,128,128,256] \n",
    "\n",
    "- Test best Config of Blocks per Layer (4 Training Runs):\n",
    "\n",
    "     Suppose the prev. test returned that 4 layers gives best valid accuracy: Run through training with 4 permutations of Blocks Per Layers (only choose either 3 or 2 blocks per layer to keep it simple) \n",
    "\n",
    "Goal: Figure out best Architecture by finding optimal Amount of Layers, and optimal Amount of Blocks per Layer.\n",
    "\n",
    "Guidelines for Architecture Test: No Dropouts, and no Data Augmentation (but normalization)\n",
    "\n",
    "### 2nd Test: Training Parameter Gridsearch\n",
    "\n",
    "2nd Test: Hyperparameter Gridsearch:\n",
    "- Learning Rate (4 tests)\n",
    "\n",
    "     LR set to [0.1, 0.01, 0.001, 0.0001] (while using ADAM as Optimizer, no LR scheduler)\n",
    "\n",
    "- Optimizer: (4 tests)\n",
    "     \n",
    "     Having figured out best LR, test different Optimizers: SGD, ADAM, ADAMW(0.01) (3 Training Runs)\n",
    "     if ADAMW returns best Valid Acc. figure out which weight decay to use [0.1,0.01,0.001,0.0001] \n",
    "\n",
    "- Exponential scheduler or not (2 differenttests. Exponential LR with gamma 0.98)\n",
    "\n",
    "Goal: Figure out best set of training-setup\n",
    "\n",
    "### 3rd Test: Data ingestion Method: \n",
    "- Batchsize [ 32, ,64, 128, 256] (4 tests)\n",
    "- Augmentation (Random Flipping, cropping) (3 Tests)\n",
    "\n",
    "     1. No Augmentation applied, \n",
    "     2. With Random Flipping and Cropping, \n",
    "     3. With Random and Cropping but copying the Altered images on top of the original training data (increase training images from 40k to 80k)     \n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters modelResnet3_443: 4697162\n",
      "NVIDIA GeForce RTX 4070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet3(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Resnet3_443Exp():\n",
    "    return ResNet3(BasicBlock, [4,4,3])\n",
    "\n",
    "model = Resnet3_443Exp()\n",
    "\n",
    "total_paramsResnet3_443 = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters modelResnet3_443: {total_paramsResnet3_443}\")\n",
    "\n",
    "# Move the model to CUDA device if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_and_evaluate_model(model, model_name, loaders, device, num_epochs=1):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    train_loss_history, valid_loss_history, valid_accuracy_history, train_accuracy_history = [], [], [], []\n",
    "    best_accuracy = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss, total_train_loss, total_correct_train, num_batches, num_train_examples = 0.0, 0.0, 0, 0, 0\n",
    "        for i, (inputs, labels) in enumerate(loaders[\"train_Enhanced\"]):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(),0.1)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            total_train_loss += loss.item() * inputs.size(0)\n",
    "            num_batches += 1\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct_train += (predicted == labels).sum().item()\n",
    "            num_train_examples += labels.size(0)\n",
    "\n",
    "            if (i + 1) % 100 == 0 or i == len(loaders[\"train_Enhanced\"]) - 1:\n",
    "                print(f\"{model_name}, train_Enhanced - Epoch: {epoch} [{(i + 1) * len(inputs)}/{len(loaders['train_Enhanced'].dataset)} \"\n",
    "                      f\"({100. * (i + 1) / len(loaders['train_Enhanced']):.0f}%)], Weight Decay: 0.0001,  Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "        avg_train_loss = total_train_loss / num_train_examples  # Correct average training loss calculation\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "\n",
    "        train_accuracy = 100. * total_correct_train / num_train_examples\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "        model.eval()\n",
    "        total_valid_loss, total_correct_valid, num_valid_batches = 0.0, 0, 0\n",
    "        for inputs, labels in loaders['valid']:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.long()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_valid_loss += loss.item() * inputs.size(0)  # Update to multiply by batch size for total loss\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_correct_valid += (predicted == labels).sum().item()\n",
    "            num_valid_batches += 1\n",
    "\n",
    "        avg_valid_loss = total_valid_loss / len(loaders['valid'].dataset)  # Correct average validation loss calculation\n",
    "        valid_loss_history.append(avg_valid_loss)\n",
    "\n",
    "        valid_accuracy = 100. * total_correct_valid / len(loaders['valid'].dataset)\n",
    "        valid_accuracy_history.append(valid_accuracy)\n",
    "\n",
    "        print(f\"End of Epoch: {epoch}, Avg. Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, Avg. Valid Loss: {avg_valid_loss:.4f}, Valid Accuracy: {valid_accuracy:.2f}%\")\n",
    "\n",
    "        if valid_accuracy > best_accuracy:\n",
    "            best_accuracy = valid_accuracy\n",
    "            model_path = f'{model_name}_Final_best_model.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"New best model saved: {model_path}\")\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    execution_time = time.time() - start_time\n",
    "    print(f\"Training completed. Total execution time: {execution_time:.2f} seconds\")\n",
    "\n",
    "    return train_loss_history, valid_loss_history, valid_accuracy_history, train_accuracy_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters modelResnet3_443_30DR: 4697162\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 2.0818\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 1.9390\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 1.8458\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 1.7741\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 1.7189\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 1.6697\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 1.6291\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 1.5897\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 1.5560\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 1.5270\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 1.4969\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 1.4718\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 1 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 1.4584\n",
      "End of Epoch: 1, Avg. Training Loss: 1.4584, Training Accuracy: 46.35%, Avg. Valid Loss: 1.2706, Valid Accuracy: 55.92%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 1.1167\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 1.1088\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 1.0922\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 1.0779\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 1.0644\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 1.0546\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 1.0448\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 1.0328\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 1.0206\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 1.0104\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 1.0005\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.9909\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 2 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.9862\n",
      "End of Epoch: 2, Avg. Training Loss: 0.9862, Training Accuracy: 65.10%, Avg. Valid Loss: 0.7222, Valid Accuracy: 74.29%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.8317\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.8337\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.8189\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.8157\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.8118\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.8034\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.7956\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.7881\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.7808\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.7730\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.7676\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.7620\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 3 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.7590\n",
      "End of Epoch: 3, Avg. Training Loss: 0.7590, Training Accuracy: 73.56%, Avg. Valid Loss: 0.6258, Valid Accuracy: 78.44%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.6568\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.6536\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.6444\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.6443\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.6422\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.6387\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.6389\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.6365\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.6324\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.6289\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.6268\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.6231\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 4 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.6208\n",
      "End of Epoch: 4, Avg. Training Loss: 0.6208, Training Accuracy: 78.44%, Avg. Valid Loss: 0.5156, Valid Accuracy: 82.42%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.5501\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.5440\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.5426\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.5456\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.5443\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.5437\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.5396\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.5376\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.5364\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.5352\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.5328\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.5309\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 5 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.5300\n",
      "End of Epoch: 5, Avg. Training Loss: 0.5300, Training Accuracy: 81.68%, Avg. Valid Loss: 0.5613, Valid Accuracy: 80.91%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.4697\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.4643\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.4731\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.4737\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.4673\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.4663\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.4638\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.4647\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.4627\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.4627\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.4611\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.4597\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 6 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.4593\n",
      "End of Epoch: 6, Avg. Training Loss: 0.4593, Training Accuracy: 84.13%, Avg. Valid Loss: 0.4121, Valid Accuracy: 86.22%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.4116\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.4152\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.4156\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.4162\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.4127\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.4116\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.4102\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.4102\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.4094\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.4087\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.4059\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.4039\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 7 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.4029\n",
      "End of Epoch: 7, Avg. Training Loss: 0.4029, Training Accuracy: 86.12%, Avg. Valid Loss: 0.4030, Valid Accuracy: 86.72%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.3743\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.3729\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.3660\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.3687\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.3679\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.3681\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.3695\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.3672\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.3640\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.3641\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.3627\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.3624\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 8 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.3622\n",
      "End of Epoch: 8, Avg. Training Loss: 0.3622, Training Accuracy: 87.53%, Avg. Valid Loss: 0.4825, Valid Accuracy: 85.11%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.3241\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.3244\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.3205\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.3229\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.3240\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.3270\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.3273\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.3280\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.3279\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.3295\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.3276\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.3265\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 9 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.3265\n",
      "End of Epoch: 9, Avg. Training Loss: 0.3265, Training Accuracy: 88.83%, Avg. Valid Loss: 0.3504, Valid Accuracy: 88.93%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.2919\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2991\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.3058\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.3053\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.3054\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.3010\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.3007\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.3014\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.3015\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.3028\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.3018\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.3005\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 10 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.3009\n",
      "End of Epoch: 10, Avg. Training Loss: 0.3009, Training Accuracy: 89.67%, Avg. Valid Loss: 0.3886, Valid Accuracy: 87.42%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.2944\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2798\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.2777\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.2831\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.2785\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.2796\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.2783\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.2791\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.2805\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.2800\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.2803\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.2799\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 11 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.2800\n",
      "End of Epoch: 11, Avg. Training Loss: 0.2800, Training Accuracy: 90.44%, Avg. Valid Loss: 0.3459, Valid Accuracy: 89.25%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.2456\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2455\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.2549\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.2549\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.2555\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.2566\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.2566\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.2554\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.2561\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.2557\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.2555\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.2570\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 12 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.2568\n",
      "End of Epoch: 12, Avg. Training Loss: 0.2568, Training Accuracy: 91.25%, Avg. Valid Loss: 0.3687, Valid Accuracy: 89.05%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.2275\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2265\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.2254\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.2319\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.2345\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.2377\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.2375\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.2393\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.2395\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.2404\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.2407\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.2400\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 13 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.2401\n",
      "End of Epoch: 13, Avg. Training Loss: 0.2401, Training Accuracy: 91.76%, Avg. Valid Loss: 0.3406, Valid Accuracy: 90.29%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.2142\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2099\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.2164\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.2207\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.2191\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.2181\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.2203\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.2208\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.2209\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.2203\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.2216\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.2220\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 14 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.2217\n",
      "End of Epoch: 14, Avg. Training Loss: 0.2217, Training Accuracy: 92.49%, Avg. Valid Loss: 0.3382, Valid Accuracy: 90.50%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.2036\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2125\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.2102\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.2074\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.2108\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.2134\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.2126\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.2122\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.2134\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.2136\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.2127\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.2119\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 15 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.2131\n",
      "End of Epoch: 15, Avg. Training Loss: 0.2131, Training Accuracy: 92.82%, Avg. Valid Loss: 0.3487, Valid Accuracy: 90.31%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.1938\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.2001\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.1988\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.2016\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.2026\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.2038\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.2028\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.2029\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.2033\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.2021\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.2011\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.2023\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 16 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.2029\n",
      "End of Epoch: 16, Avg. Training Loss: 0.2029, Training Accuracy: 93.09%, Avg. Valid Loss: 0.3427, Valid Accuracy: 90.39%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.1717\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.1839\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.1883\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.1899\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.1895\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.1901\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.1929\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.1962\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.1956\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.1959\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.1955\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.1963\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 17 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.1964\n",
      "End of Epoch: 17, Avg. Training Loss: 0.1964, Training Accuracy: 93.39%, Avg. Valid Loss: 0.3997, Valid Accuracy: 89.57%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.1676\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.1746\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.1750\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.1779\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.1775\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.1784\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.1805\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.1798\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.1803\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.1812\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.1820\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.1819\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 18 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.1824\n",
      "End of Epoch: 18, Avg. Training Loss: 0.1824, Training Accuracy: 93.87%, Avg. Valid Loss: 0.3442, Valid Accuracy: 90.60%\n",
      "New best model saved: modelResnet3_443_30DR_Final_best_model.pth\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.1625\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.1663\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.1741\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.1753\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.1741\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.1736\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.1725\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.1743\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.1743\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.1747\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [70400/80000 (88%)], Weight Decay: 0.0001,  Loss: 0.1762\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [76800/80000 (96%)], Weight Decay: 0.0001,  Loss: 0.1756\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 19 [80000/80000 (100%)], Weight Decay: 0.0001,  Loss: 0.1760\n",
      "End of Epoch: 19, Avg. Training Loss: 0.1760, Training Accuracy: 94.05%, Avg. Valid Loss: 0.3648, Valid Accuracy: 90.53%\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [6400/80000 (8%)], Weight Decay: 0.0001,  Loss: 0.1680\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [12800/80000 (16%)], Weight Decay: 0.0001,  Loss: 0.1689\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [19200/80000 (24%)], Weight Decay: 0.0001,  Loss: 0.1710\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [25600/80000 (32%)], Weight Decay: 0.0001,  Loss: 0.1739\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [32000/80000 (40%)], Weight Decay: 0.0001,  Loss: 0.1747\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [38400/80000 (48%)], Weight Decay: 0.0001,  Loss: 0.1743\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [44800/80000 (56%)], Weight Decay: 0.0001,  Loss: 0.1750\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [51200/80000 (64%)], Weight Decay: 0.0001,  Loss: 0.1753\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [57600/80000 (72%)], Weight Decay: 0.0001,  Loss: 0.1754\n",
      "modelResnet3_443_30DR, train_Enhanced - Epoch: 20 [64000/80000 (80%)], Weight Decay: 0.0001,  Loss: 0.1748\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Re-initialize the model for each weight decay to ensure training starts fresh\u001b[39;00m\n\u001b[0;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m ResNet3_with_dropout_30DR()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 21\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodelResnet3_443_30DR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Unpack and store the returned metrics\u001b[39;00m\n\u001b[0;32m     25\u001b[0m all_metrics_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m'\u001b[39m], \\\n\u001b[0;32m     26\u001b[0m all_metrics_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_losses\u001b[39m\u001b[38;5;124m'\u001b[39m], \\\n\u001b[0;32m     27\u001b[0m all_metrics_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_accuracies\u001b[39m\u001b[38;5;124m'\u001b[39m], \\\n\u001b[0;32m     28\u001b[0m all_metrics_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_accuracies\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m metrics\n",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[1;34m(model, model_name, loaders, device, num_epochs)\u001b[0m\n\u001b[0;32m     15\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\Documents\\PythonProjects\\DeepLearning\\DL_Sp24_Miniproject\\models.py:62\u001b[0m, in \u001b[0;36mResNet3Dropouts.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     60\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(out)\n\u001b[0;32m     61\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(out)\n\u001b[1;32m---> 62\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(out)\n\u001b[0;32m     64\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(out\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1519\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1528\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1527\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1530\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1531\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\Documents\\PythonProjects\\DeepLearning\\DL_Sp24_Miniproject\\models.py:26\u001b[0m, in \u001b[0;36mBasicBlockDropouts.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 26\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(out)  \u001b[38;5;66;03m# Apply dropout after activation (new proposed method) https://arxiv.org/pdf/1904.03392.pdf\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out))\n",
      "File \u001b[1;32mc:\\Users\\Citylab\\.conda\\envs\\torchenv2\\lib\\site-packages\\torch\\nn\\functional.py:1471\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming Resnet3_443 is defined and device is set\n",
    "# model = Resnet3_443().to(device)\n",
    "num_epochs = 200  # Or any other number of epochs you want to train for\n",
    "\n",
    "all_metrics_final = {\n",
    "    'train_losses': [],\n",
    "    'valid_losses': [],\n",
    "    'valid_accuracies': [],\n",
    "    'train_accuracies': []\n",
    "}\n",
    "\n",
    "def ResNet3_with_dropout_30DR():\n",
    "    return ResNet3Dropouts(BasicBlockDropouts, [4, 4, 3], dropout_rate=0.3)  # For example, a dropout rate of 0.5\n",
    "\n",
    "modelResnet3_443_30DR = ResNet3_with_dropout_30DR()\n",
    "total_paramsResnet3_443_30DR = sum(p.numel() for p in modelResnet3_443_30DR.parameters())\n",
    "print(f\"Total parameters modelResnet3_443_30DR: {total_paramsResnet3_443_30DR}\")\n",
    "\n",
    "# Re-initialize the model for each weight decay to ensure training starts fresh\n",
    "model = ResNet3_with_dropout_30DR().to(device)\n",
    "metrics = train_and_evaluate_model(model, \"modelResnet3_443_30DR\", loaders, device, num_epochs)\n",
    "\n",
    "\n",
    "# Unpack and store the returned metrics\n",
    "all_metrics_final['train_losses'], \\\n",
    "all_metrics_final['valid_losses'], \\\n",
    "all_metrics_final['valid_accuracies'], \\\n",
    "all_metrics_final['train_accuracies'] = metrics\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Training Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(all_metrics_final['train_losses'], label='Train Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Validation Loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(all_metrics_final['valid_losses'], label='Validation Loss')\n",
    "plt.title('Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Validation Accuracy\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(all_metrics_final['valid_accuracies'], label='Validation Accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "# Training Accuracy\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(all_metrics_final['train_accuracies'], label='Training Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet3(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best Model\n",
    "model_path = 'Resnet3_443_Exp_Final_best_model.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test images:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "test_data_dict = unpickle('./data/cifar_test_nolabels.pkl')\n",
    "test_images = test_data_dict[b'data']\n",
    "test_images = test_images.reshape(-1, 3, 32, 32)\n",
    "\n",
    "# Modified function to show random images\n",
    "def show_original_random_images(images, rows=2, cols=5):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
    "    indices = np.random.choice(len(images), rows*cols, replace=False)  # Select random indices\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Use the random index to select an image\n",
    "        img = images[indices[i]].transpose(1, 2, 0)\n",
    "        ax.imshow(img.astype('uint8'))\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print('test images:')\n",
    "# Show 10 random original images\n",
    "show_original_random_images(test_images, rows=2, cols=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resnet3_443_Exp_Final_best_model.pth'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'submission.csv'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Best Model, Normalize test data, do an inference and create submission csv file\n",
    "\n",
    "# Convert test_images to a float tensor\n",
    "test_images = torch.from_numpy(test_images).float()\n",
    "\n",
    "# If the pixel values are in [0,255], scale them to [0,1]\n",
    "if test_images.max() > 1.0:\n",
    "    test_images /= 255.0\n",
    "\n",
    "# Permute the images to [N, C, H, W] format\n",
    "test_images = test_images.permute(0, 1, 2, 3)\n",
    "\n",
    "\n",
    "# Define the normalization transform\n",
    "normalize = transforms.Normalize(*stats) #takes mean and std from loadingand transforming the validation data\n",
    "\n",
    "# Normalize the images\n",
    "normalized_images = torch.stack([normalize(img) for img in test_images])\n",
    "\n",
    "# Make sure your model is on the right device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#load best model.pth\n",
    "# model.load_state_dict(torch.load('best_model.pth'))\n",
    "# Load the model state dict into the model\n",
    "\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Now, ensure your input data is also sent to the same device\n",
    "normalized_images = normalized_images.to(device)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "predictions = []\n",
    "with torch.no_grad():  # No need to track gradients\n",
    "    for img in normalized_images:\n",
    "        img = img.unsqueeze(0).to(device)  # Add batch dimension and ensure the tensor is on the right device\n",
    "        output = model(img)  # Process each image individually\n",
    "        pred = output.argmax(dim=1)  # Get the index of the max log-probability\n",
    "        predictions.append(pred.item())\n",
    "print(len(predictions))\n",
    "\n",
    "# Create a DataFrame with the ID and predicted Labels\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': list(range(len(predictions))),\n",
    "    'Labels': predictions\n",
    "})\n",
    "\n",
    "# Define the submission CSV file path\n",
    "submission_csv_path = 'submission.csv'\n",
    "# Save the DataFrame to a CSV file, without the index\n",
    "submission_df.to_csv(submission_csv_path, index=False)\n",
    "\n",
    "# Returning the path to the saved CSV file\n",
    "submission_csv_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
